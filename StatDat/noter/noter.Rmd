---
title: "Noter"
output: html_document
date: "2024-10-17"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Latex
$$ \mu \: \:  \sigma \: \: \alpha \: \: \beta $$

$$ \hat{x} \: \: \overline{x} \: \: \frac{x}{y}$$
$$ x-\texttt{Ord} $$

# Data
Indlæsning
```{r}
#install.packages("ggplot2")
library(ggplot2)

# txt
data_johnson <- read.table("../data/johnson-fatpct.txt", header = 1)
pestgolf <- read.table("../data/pestgolf.txt", header = 1)

# xls
library(readxl)
studData2 <- read_excel("data/stud2017-v2.xls")
studData2 <- studData2[,  c("kon", "hojde")]
studData2 <- na.omit(studData2) # Drop null rows

# lib
library(MASS)
data(cats)
cats <- na.omit(cats) # Drop null rows


```

Print data
```{r}
head(pestgolf, n = 3) # Øverste rækket
unique(pestgolf$Lokation) # Unikke værider 
```


Ændring i data
```{r}
# Opret subset af data med filter
kData <- subset(studData2, kon=="Kvinde")
mData <- subset(studData2, kon=="Mand")
```




# Modeller
## 1-stikprøve T-test
**Data:** <br>
Kontinuert responsvariabel [y] med ingen forklarende variabel
$$y_1, ..., y_n$$

**Statistisk model:** <br>
$y_1, ..., y_n$ er  uafhængige og alle normalfordelte
med samme middelværdi $\mu_i = \gamma+e_i $ hvor $e_i \sim N(0, \sigma^2)$ og samme spredning $\sigma$.

**De ukendte populationsparametre** <br>
Middelværdi $\mu$ og spredning $\sigma$


## 1-sidet Anova
Pointen med en varaiansanalyse er at vi kan påvise forskelle mellem grupper ved at samligne forskellige kilder til variation.

**Data:** <br> $y_1, ..., y_n$ [Forklar var de repræsentere] fra k grupper med $n_j$ observationer i gruppe j.

**Statistisk model:** <br>
Vi antager at $y_1, ..., y_n$ er uafhængige og normalfordelte $\sim N(\mu_i, \sigma^2)$

Dertil antager vi at middelværdien $\mu_i = \alpha_{g(i)} + e_i$ hvor
$\epsilon_i \sim N(0, \sigma^2)$ afhænger af gruppen. Med samme spredning $\sigma$ i alle grupper. 

**De ukendte populationsparametre** <br>
Middelværdien for alle grupper $\mu_1 ,..., \mu_k$ og den ukendte spredningen $\sigma$

## 2-stikprøve T-test
TODO : Tilføj afsnit

## Linær regression

**Data:** <br> Par $(x_1, y_1), ..., (x_n, y_n)$ bestående af
kvantitative kontinuerte data, både for vores responsvariabel [y] og den
forklarende variabel [x].

**Statistisk model:** <br> $$ y_i = \mu_i + \epsilon  $$ hvor
$\epsilon_i \sim N(0, \sigma^2)$

Vi antager $y_1 ,..., y_n$ er uafhængihed, og at alle $y_i$ er
normaltfordelt med middelværdi $\mu_i = \alpha + \beta x_i$ (ret linje)
med spredning $\sigma$.

**De ukendte populationsparametre** <br> Skæringen $\alpha$, hældningen
$\beta$ og spredningen $\sigma$ er alle ukendte parametre, som vi kan
estimere: $\hat{\alpha},\hat{\beta},  \hat{\sigma}$

## Kvadratisk regerssion
**Data:** <br> Par $(x_1, y_1), ..., (x_n, y_n)$ bestående af
kvantitative kontinuerte data, både for vores responsvariabel [y] og den
forklarende variabel [x].

**Statistisk model:**
$$y_i = \alpha + \beta_1 x_{i} + \beta_2 x_{i}^2 + e_i$$
hvor $\epsilon_i \sim N(0, \sigma^2)$

Vi antager $y_1 ,..., y_n$ er uafhængihed, og at alle $y_i$ er
normaltfordelt med middelværdi $y_i = \alpha + \beta_1 x_{i} + \beta_2 x_{i}^2 + e_i$ (Andengrads polynomial)
med spredning $\sigma$.

**De ukendte populationsparametre** <br> 
Skæringen $\alpha$, hældningenskoeficienter $\beta_1, \beta_2$  og spredningen $\sigma$ er alle ukendte parametre, som vi kan
estimere: $\hat{\alpha},\hat{\beta_1}, \hat{\beta_2}, \hat{\sigma}$

**Eksempel**
```{r}

```



## 2-Sidet Anova evt. med vekselvirkning

### Additive model for tosidet ANOVA
**Data** <br>
To kategoriske forklarende variable og en kontinuert.
[Her skal der skrives i sammenhæng af data, men angiv grupperne $x_1$ og $x_2$ samt responsvariablen $y_i$]

**Statistisk model**
$$ y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + e_i $$
hvor $\epsilon_i \sim N(0, \sigma^2)$

**Eksempel**
```{r}
unique(pestgolf$Treat)
unique(pestgolf$Lokation)
```


```{r}
m1 <- lm(Kd ~ Treat + Lokation, data = pestgolf)
summary(m1)
```

Vi ser at TreatT04 og LokationDYR mangler i tabellen, da må dette være vores kontrol parameter / Intercept

Vi kan estimere middelværdien for Lokation = "HONE", Treat = "T05" ved brug af tabellen

```{r}
# Intercept + Treat05 + LokationHONE 
0.89411 + 0.22411 + (-0.46350)
```

Eller ved brug af predict
```{r}
predict(m1, data.frame(Lokation = "HONE", Treat = "T05"), interval = "p")
```


### Additive model med vekselvirkning
To kategoriske forklarende variable og en kontinuert.
[Her skal der skrives i sammenhæng af data, men angiv grupperne $g_1(i)$ og $g_2(i)$ samt responsvariablen $y_i$]

**Data** <br>
To kategoriske forklarende variable og en kontinuert.
[Her skal der skrives i sammenhæng af data, men angiv grupperne $g_1(i)$ og $g_2(i)$ samt responsvariablen $y_i$]

**Statistisk model**
$$ y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1x_2 + e_i $$

hvor $e_i \texttt{ iid. } N(0, \sigma^2)$

**Eksempel**
```{r}
m2 <- lm(Kd ~ Treat + Lokation + Treat * Lokation, data = pestgolf)
summary(m2)
```

Vi ser at TreatT04 og LokationDYR mangler i tabellen, da må dette være vores kontrol parameter / Intercept

Vi kan estimere middelværdien for Lokation = "HONE", Treat = "T05" ved brug af tabellen

```{r}
# Intercept + Treat05 + LokationHONE + TreatT05:LokationHONE
0.848667 + 0.315000 + -0.459333 + (-0.008333)
```

Eller ved brug af predict
```{r}
predict(m2, data.frame(Lokation = "HONE", Treat = "T05"), interval = "p")
```
### Hypotese test af vekselvirkning

$h_0: \beta_3 = 0$

Kan testes med anova eller drop1
```{r}
anova(m1, m2)
cat("\n\n\n------------------------------------------------------------------\n")
drop1(m2, test="F")
```

Vi forkaster ikke 0 hypotesen på et signifikansniveau på 95% da vi for en p-værdi på 0.0682 

## ANCOVA (Flere rette linjer)
**Data**
De forklarende variabel består af en kontinuert variabel x [forklar X], og en kategorisk variabel grp [Forklar grp]. Respons variablen $y_i$ er kontinuert

**Statistisk model**
**Additativ**
$$ y_i = \alpha_{\texttt{grp(i)}} + \beta \cdot x_i + \epsilon_i $$

hvor $\epsilon_i \texttt{ iid. } N(0, \sigma^2)$

Som det ses i formlen for middelværdien angivet overfor, er effekten af x ikke afhængig af gruppen. Således for vi en model med flere parallele linjer med hældningskoefficent $\beta$ og skæring $\alpha_{\texttt{grp(i)}}$

**Parameter**
Skæringen per gruppe $\alpha_{\texttt{grp(i)}}$, hældningen $\beta$ og spredningen $\sigma$ er alle ukende populationsparametre, som vi kan estimere.




## Multilineær regression / Multipel lineær regression
Modeller med $d\geq2$ kvantitative forkl. variable.
$$y_i = \alpha + \beta_1 x_{i1} + ... + \beta_d x_{id} + e_i$$
**Data** <br>
Tupler af data $(x_{11}, x_{11}, y_1), ... , (x_{n1}, x_{n1}, y_n) $ med forklarende variable [Beskriv x'erne] og respons variabel [Beskriv y]

**Statistisk model** <br>
Udgangspunkt i to forklarende variable:
$$y_i = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + e_i$$ 
hvor $e_i \sim N(0, \sigma^2)$

**De ukendte populationsparametre** <br> 
De partielle hældninger $\beta_1$, $\beta_2$, skæring med y aksen $\alpha$ og spredningen $\sigma$ er populationsparametre som vi kan estimere: $\hat{\beta_1}, \hat{\beta_2}, \hat{\alpha}, \hat{\sigma} $

**Multikollinearitet**
Multikollinearitet opstår hvis $x_1$ og $x_2$ er afhængie, således at det bliver svært at adskille effekten af dem. 

Vi skal altid være opmærksom på kollinearitet, og tegn på dette kunne være:
  * Unaturlige estimater (Forkert fortegn)
  * Hverken $\beta_1$ eller $\beta_2$ er signifikante

Vi har den statistisk model
$$y = \beta_0 + \beta x_{1} + \beta_2 x_2 + \epsilon $$

Men hvis der er lineær afhængighed gælder det at

$$ x_2 \approx  a + b x_1 $$

Hvilket implicere
$$ y \approx \beta_0 + \beta x_{1} + \beta_2 (a + b x_1) + \epsilon $$
hvor
$$ \epsilon \sim N(0, \sigma^2) $$

### Eksempel på anvendelse
**Fit modelen**
```{r}
m1 <- lm(bodyfat ~ hip + abdomen, data = data_johnson)
summary(m1)
```

Vi estimere en model $$ \hat{y} = \hat{\alpha} +  \hat{\beta_1}x + \hat{\beta_2}x  $$
hvor $\hat{\alpha} = -20.88$ er et estimat for skæringen, $\hat{\beta_1} = -0.33 $, $ \hat{\beta_2} = 0.78$ er estimater for hældningen.

Vi ser at hip skifter fortegn, beskriv problemet med Multikollinearitet. Kan vi argumentere for at de forklarende variable er afhænige?

**Test af hypotese**
Vi ønsker at teste $h_0: \beta_1 = -0.5, \beta_2 = 0.8$

Vi anvender en F-test til at teste hele hypotesen:
  * Fullmodel: Vores fittede multiple regressions model
  * Nulmodel: En multiple regressions model med fixed partielle hældninger $\beta_1 = -0.5, \beta_2 = 0.8$

```{r}
m2 <- lm(bodyfat ~ offset((-0.5)*hip + (0.8)*abdomen), data = data_johnson) ## Nulmodel

anova(m2, m1)

```
Vi forkaster nulhypotesen med en signifikantsnivue på 95% med en p-værdi på 0.0025.  

## Lineær normal model 
TODO : Tilføj afsnit

## Binomial model
TODO : Tilføj afsnit

## Antalstabel / ro proportioner
TODO : Tilføj afsnit

# Kontrol af modelantagelser
**kvadratisk regression, en stikprøve, ensidet ANOVA, lineær regression**
Antagelser:
 * $e_1, ..., e_n$ eller $y_1, ..., y_n$ er uafhængige
 * Alle $e_i$ eller $y_i$ er normal fordelte
 * Alle $e_i$ eller $y_i$ har samme spredning
 * Middelværien har den rette form
 
**Uafhængihed** <br>
Antagelsen on uafhængighed er mest et spørgsmål om designet af eksperimentet eller dataindsamlingen.
  * Er der flere målinger på samme eksperimentelle enhed?
  * Er individerne i familie med hinanden?
  * Hører observationerne naturligt sammen i grupper?

Hvis ja, så er der måske problemer med uafhængighedsantagelsen,

**Samme spredning** <br>
Kontrolleres med residual plot
```{r}
plot(fitted(linreg), rstandard(linreg))
abline(0,0, col = 'Red')

```

Der må være noget mønster i den lodrette variation
  * Hvis vi kan se en kurve er middelværdien forkert. En parabel i overstående tilfælde vil formentlig betyde vi skal anvende kvadratisk regression
  *  Punkterne udgør en slags trag, viser at spredningen stiger med middelværdien hvilket er et tegn på Variansinhomogenitet
  
Derudover kan det give mening at være opmærksom på outliers 95% af punkterne bør ligge indenfor (-2, 2)

**Normalt fordelt** <br>
```{r}
qqnorm(rstandard(linreg))
abline(0,1, lty=2)
```

Der må ikke være nogen systemeatisk afvigelse fra den ligefrem propotionelle linje. (Den er kun ligefrem propotionel fordi vi tester for residual spredningen)

# Grafer og plots
## Scatter
```{r}
linreg <- lm(Hwt ~ Bwt, data = cats) ### estimer regressionslinje (Kun nødvendig for abline)
plot(cats$Bwt, cats$Hwt, xlab = "Bodyweight(kg)", ylab = "Heart weight (g)", main = "Cats data")
abline(a = -0.3567, b = 4.0341, col = "red") # a = skæring, b = hældning
```

## QQplot
```{r}
qqnorm(cats$Bwt, main="Title")
abline(mean(cats$Bwt), sd(cats$Bwt), lwd = 1, col = "red")

```
Kontroler efter systematisk afvigelse, hvis der sker en tydelig krumning skal data formentlig log-transformeres.


## Normalfordeling
Kan laves med r-plot
```{r}
hist(kData$hojde, prob = TRUE, xlab = "Hojde", main = "Kvinder", col = "lightgrey")
f1 <- function(x) dnorm(x, mean = mean(kData$hojde), sd = sd(kData$hojde))
plot(f1, 150, 190, col = "red", add = TRUE, lwd = 3)  
```

Men hvis det skal skraveres anvend GGplot

```{r}
data_mean = 41.5 
data_sd = 1.4

p_1 <- pnorm(q = c(42.2), sd = data_sd, mean = data_mean, lower.tail = TRUE) # Mindre end 42
p_2 <- pnorm(q = c(40), sd = data_sd, mean = data_mean, lower.tail = TRUE) # Mindre end 40
p_1 - p_2

ggplot(data.frame(x = c(data_mean - 5, data_mean + 5)), aes(x)) +
  stat_function(fun = dnorm, n = 1000, args = list(mean = data_mean, sd = data_sd)) +
  # Coloring
  stat_function(fun = dnorm, args = list(mean = data_mean, sd = data_sd),
                xlim = c(40, 42.2), # Defines the interval
                geom = "area", fill = "blue") +
  labs(x = "Marginalskatteprocent", y = "Densitet")
```



## Boxplot
```{r}
# Kontinuert ~ kategorisk
boxplot(cats$Hwt ~ cats$Sex)
```

En stor between-group variation er et tegn på der er forskel på gruppe gennemsnittene, men hvis within-group varaiationen også er stor, kan det være et tegn på at forskellen skyldes tilfældig variation.

## Histogram
```{r}
hist(log(cats$Hwt), # Data
     xlab="Body weight (kg)", # X label
     main="Cats: Body weight", # Title
     nclass=20, # Antal søjler
     prob=TRUE, # Samlet areal = 1
     col = "blue") # Farve

```

# Generalt
## Fejltyper
Type 1 - Afvise nulhypotesen hvis den er sand
Type 2 - Ikke afvise nulhypotesen hvis den er falsk

Bemærk:
"Vi konkluderer at der ikke er nogen sammenhæng mellem x og y, selvom der i virkeligheden er en sammenhæng" er en type 2 fejl. Fordi at konkludere at der ikke er nogen sammenhæng er det samme som ikke at afvise hyposten. Og at der er en sammenhæng er det samme som at 0-hypostesen er falsk.

# Noter til quiz
## uge 2
### Konfidensintervallet for enkelt stikprøve
**Giver standard error**
$$ \hat{y} \pm t_{0.975, n-1} \cdot SE $$
$$ n = 7, \mu = 17, SE = 3  $$
```{r}
# mu - qt * s/sqrt(n)
n = 7
mu =17
SE = 3

mu + c(-1, 1) * qt(0.975, df=n-1) * SE
```
**Givet spredning**
$$ \hat{y} \pm t_{0.975, n-1} \cdot \frac{s}{\sqrt{n}} $$
```{r}
# mu - qt * s/sqrt(n)
n = 7
mu =17
s = 3

mu + c(-1, 1) * qt(0.975, df=n-1) * (s/sqrt(n))
```

### Find spredning for Normalfordeling givet middelværdi og konfidensinterval på 68%

```{r}
lower = 50
upper = 62

(upper - lower) / 2

```
### Sandsynlighed for Observation over værdi for normal fordeling
Vi får givet middelværdi og spredning

```{r}
mu = 200 # Middelværdi
s = 40 # Spredning
obs = 190 #Observation

# Under
pnorm(obs, mean = mu, sd = s)

#Over
1 - pnorm(obs, mean = mu, sd = s)
```

### Mere end 2 spredninger væk fra middelværdien?
For en normalfordeling fås et nogenlunde 95% interval ved
$$ \hat{y} \pm 2 \cdot \frac{s}{\sqrt{n}} $$
Altså ligger 5% af observationerne fra en normalfordelt population mere end 2*spredning vær fra middelværdien

### Sandsylighed mellem 2 værdier for normalfordeing
```{r}
mu = 15.5 # Middelværdi
s = 3 # Spredning
upper = 16.5 # Til
lower = 14 # Fra

pnorm(upper, mean = mu, sd = s) 
pnorm(lower, mean = mu, sd = s)
cat("\n")
pnorm(upper, mean = mu, sd = s) - pnorm(lower, mean = mu, sd = s)
```

### Find den værdi, hvor vi kan forvente at x% af oberservationerne ligger under.
```{r}
mu = 114.8 # Middelværdi
s = 13.1 # Spredning
x = 0.35 # percentage to check

qnorm(x, mean = mu, sd = s)
```
### Beregn SE udfra spredning
SE fra spredning
```{r}
s = 2
n = 16

s / sqrt(16)
```

## uge 3
### Bestem t-teststørrelsen og p-værdien for hypotesen i lineær regression
I en lineær regression med 87 datapunkter er hældningen blevet estimeret til 5.12 med en standard error på 3.20. Bestem t-teststørrelsen og p-værdien for hypotesen om at "den sande hældning" er 0
```{r}
beta = 5.12 #Hældning
SE = 3.2 # Standard error
n = 87 # Antal observationer
hypotese = 0 # hypotesen om at "den sande hældning" er 0


# Test af hypotesen H: beta=4
T = (beta - hypotese) / SE

# Beregning af p-vaerdi
P = 2*(1-pt(T, df = n - 2))

T
P

```
### Konfidensinterval for hældning i lineær regression
I en lineær regression med 104 observationer er hældningen blevet estimeret til 33.2 med en tilhørende standard error på 2.8. Bestem et 95% konfidensinteval for hældningen.

```{r}
n = 104 # Antal observationer
beta = 33.2 # Hældning
SE = 2.8 # Standard error
int = .95 # Konfidensinterval
conf = 1 - (1 - int) /2
conf

# 2 frihedsgrader for lineær regression
beta + c(-1, 1) * qt(conf, df=n-2) * SE

```

### Ensidet ANOVA t-fraktil (TODO: Forkert, svaret er 2.002465 )
Ved en ensidet variansanalyse med 20 observationer fra hver af tre forskellige behandlingsgrupper (A, B og C) ønsker man at konstruere et 95 % - konfidensinterval for den gennemsnitlige værdi hørende til målinger fra gruppe A. Angiv værdien af den t-fraktil der indgår i konstruktionen af konfidensintervallet.

```{r}
n <- 20 # Antal Observationer
k <- 1 # Antal grupper (I gruppe A)

qt(0.975, df = n-1)
```
## Uge 4
### Konklusion af p-værdi givet f-fraktil og f-teststørrelse
Man vil sammenligne grupperne i en ensidet ANOVA med 100 observationer og fire grupper med et F-test. Man beregner F-teststørrelsen til 4.19, og 95%-fraktilen i F(3,96) er 2.70. Hvad kan vi sige om p-værdien?

Da
$$ \texttt{p-value} = P(F \geq F_{obs}) $$

har vi at siden F-teststørrelsen (4.19) er større end  fraktilsen (2.70) så er p-værdien er lavere end 0.05 og vi kan afvise at grupperne har samme middelværdi.

### Konklusion af p-værdi givet to f-fraktil og f-teststørrelse
Vi er i gang med at udføre et t-test og får en observeret teststørrelse på T = 1.99. I den relevante t-fordeling er 97.5% fraktilen lig 2.14, mens 95% fraktilen er 1.76.

Da teststørrelse (1.99) ligger mellem 97.5% fraktilen (2.14) og 95% fraktilen er 1.76. (1.76) ligger p-værdien mellem 0.05 og 0.10

  * Mindre end 97.5% fraktilen ==> Større end 0.05
  * Større end 95% fraktilen ==> Mindre end 0.10

### Bestem t-teststørrelsen og p-værdien for hypotesen i lineær regression

```{r}
beta = 3.19 #Hældning
SE = .89 # Standard error
n = 52 # Antal observationer
hypotese = 0 # hypotesen om at "den sande hældning" er 0


# Test af hypotesen H: beta=4
T = (beta - hypotese) / SE

# Beregning af p-vaerdi
P = 2*(1-pt(T, df = n - 2))

T
P

```
### Sandsylighed for værdi lavere end givet mean og sd
```{r}
pnorm(0, mean = 4, sd = 2.8)

```


