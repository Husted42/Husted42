---
title: "GAVEN pt.2"
output:
  pdf_document: default
  html_document: default
---

UGE 1: 
#Beskrivelse og indl√¶sning af data 
Altid start med at finde/downloade dit datas√¶t ved "import datasat" eller downloade en pakke. 
```{r}
library(MASS)
data(cats)
```
Viser de tre variable der findes i datas√¶ttet: 
```{r}
head(cats)
```

Hvis jeg kun vil forhold mig til en af variablerne: 
```{r}
bwt <- cats$Bwt
```

Stikpr√∏vest√∏rrelser: 
```{r}
middelv√¶rdi <- mean(cats$Bwt)
spredning <- sd(cats$Bwt)
varians <- var(cats$Bwt)
median <- median(cats$Bwt)
summary <- summary(cats$Bwt)
```

#Tabeller: 
Laver en tabel kun for k√∏nnet
```{r}
table(cats$Sex)
```

#Visualisering: 
SCATTERPLOT, bruges til sammenh√¶ngen mellem to numeriske/kontinuerte variable 
```{r}
scatter <- plot(cats$Hwt ~ cats$Bwt)
```

BOXPLOT: 
Viser de numriske m√•linger der markerer 25%, medianen og 75%
```{r}
boxplot(cats$Hwt, main="Heart Weight", col="lightgray")
```

HISTOGRAM: 
Bruges til at vise fordelingen af numerisk/kontinuert/kvantitativ variabel i en testst√∏rrelse 
```{r}
par(mfrow=c(1,2)) #placerer dem ved siden af hinanden 
hist(cats$Bwt)
hist(cats$Hwt)
```

#Line√¶r regression 
Hvis Bwt er nyttig, for at kunne forudsige Hwt, derfor bruger jeg regressionsanalyse, for at kunne beskrive sammenh√¶ngen mellem to kvantitative variable. Responsvar: Hwt og forklar.var: Bwt 

LIGNINGEN: y = a*x+b 
y = Hwt og x = Bwt 

```{r}
linreg <- lm(Hwt ~ Bwt, data = cats) #estimerer regressionslinjen
linreg
```
Kan ud fra dette se, at estimatet for linjens sk√¶ring som er intercept = -0.3567 
Linjens h√¶ldning, som er Bwt = 4.0341 
Fortolkning: Hver gang kropsv√¶gten √∏ges med 1 kg, vil hjertev√¶gten for√∏ges med 4.0341 g i gennemsnit 

Bruger abline, for at indtegne den fittede reglinje og inds√¶tter mine estimater: 
```{r}
plot(cats$Bwt, cats$Hwt)
abline(-0.3567, 4.0341) 
```
Kan her ogs√• lave summary, og confint, for at se alle v√¶rdierne og 95%-konfidensinterval

#Korrelationer
Disse bruges, for at forklare sammenh√¶ngen mellem x og y. 
Den er 0, hvis der ikke er en sammenh√¶ng 
+1 eller -1, hvis der er perfekt sammenh√¶ng 
```{r}
cor(cats$Bwt, cats$Hwt)
```

#Beregning af estimat og konfidensinterval for punkt p√• linjen 

Eksempel: Vi er interesseret i estimat og KI for hjertev√¶gt med en kropsv√¶gt p√• 2,5 kg. 
For at beregne estimatet, skal man lave et fiktivt datapunkt ved x=2.5: 
```{r}
newdata <- data.frame(Bwt=2.5)
```
Og for at findes estimatet ved dette, bruges predict: 
```{r}
predict(linreg, newdata)
```
For at finde estimaetet og 95%-konfidensinterval bruges ogs√• predict: 
```{r}
predict(linreg, newdata, interval="confidence", level=0.95)
```
Den gennemsnitslige hjertev√¶gt blandt katte p√• 2.5 kg estimeres til 9.72 g med 95% konfidensinterval (9.46, 9.99). Bem√¶rk at dette interval udtaler sig om gennemsnittet (af hjertev√¶gten) for katte med kropsv√¶gt p√• 2.5 kg - ikke om v√¶rdien for en enkelt kat. Konfidensintervallet skal ikke fortolkes s√•dan, at det vil indeholde ca. 95 % af fremtidige m√•linger for katte med kropsv√¶gt p√• 2.5 kg.

#t.test for line√¶r regression

Hypotesen om at der ikke er sammenh√¶ng mellem kropsv√¶gt og hjertev√¶gt, H0:Œ≤=0, testes med et t-test.
```{r}
summary(linreg)
```
Vi f√•r en p-v√¶rdi som er under 2‚ãÖ10‚àí16, (hvilket i praksis er 0!), s√• hypotesen forkastes. Der er st√¶rk evidens for at der er en sammenh√¶ng, hvilket n√¶ppe er s√¶rligt overraskende.


#Ensidet variansanalyse

V√¶rdien er m√•lt af en kvantitiav variabel og m√•lingens grupper er inddelt af en kategorisk variable - vil man se, om responsvariablen er ens i de forskellige grupper 
```{r}
library(isdals)
data(antibio)
```
Vil forklare variationen i m√¶ngden af organisk stof(org) ud fra en forklarende variable(type)

Starter ALTID med at visualisere med at boxplot 
```{r}
figur1 <- boxplot(antibio$org ~ antibio$type)
```

#Ensidet ANOVA 
Fokuserer p√• sammenligning af gruppegennemsnit
```{r}
lm(org ~ type -1, data=antibio)
```



UGE 2: 
#Indl√¶sning af data 
Her udv√¶lger jeg kun to variable fra datas√¶ttes: 
```{r}
library(readxl)
studData2 <- stud2017_v2 <- read_excel("Downloads/stud2017-v2.xls")
studData2 <- studData2[, c("kon", "hojde")]
```
Det h√¶nder, at den ikke vil downloade den s√•dane, men s√• √¶ndrer den til "read_excel("stud2017-v2.xls)

*SUBSET*

Hvis jeg vil opdele m√¶nd og kvinder: 
```{r}
kData <- subset(studData2, kon == "Kvinde")
mData <- subset(studData2, kon == "Mand")
```

Hvis der er missin value og den giver NA, hvis du vil finde spredningen for kvinders h√∏jde f.eks: 
```{r}
sd(kData$hojde) #forkerte m√•de 
```
```{r}
sdK <- sd(kData$hojde, na.rm = T)
```

#Beregning af sandsynligheder og fraktiler i en normalfordeling 

Laver et histogram og prob=TRUE, da det sikrer at arealet er lig 1 alle steder 
```{r}
hist(kData$hojde, prob = TRUE)
```
Udregner forskellige sandsynligheder for y, hvis jeg ved at mean = 168.63 og spredning = 6.64
```{r}
#hvis P(y <= 160)
pnorm(160, mean=168.63, sd=6.64)
```
Hvis jeg vil finde 90%-fraktilen, hvis b=0,096 
```{r}
qnorm(0.09685211, mean=168.63, sd=6.64)
```

rnorm bruges, n√•r man skal simulere et datas√¶t ud fra normalfordelt data 

#QQ-plot 
Viser om data er en normalfordeling 
```{r}
qqnorm(kData$hojde)
abline(168.63, 6.64)
```
Her kan man se, at de ligner flot p√• en ret linje og derfor kan man med rimelighed beskrive varationen af vores data ved en normalfordeling 

UGE 3: 
#Ensidet ANOVA 
Hvordan estimerer man parametrerene, ergo hvordan finder man punktestimaterne - bruger igen antibio 

Laver en model, der parametriserer de seks gennemsnit: 
```{r}
model1 <- lm(org ~ type -1, data=antibio)
summary(model1)
```
```{r}
confint(model1)
```
Hvis jeg ikke havde skrevet "-1", s√• vil referencegruppen v√¶re den der kommer f√∏rst i alfabetet. 

#skift af referencegruppe 
```{r}
antibio$type <- relevel(antibio$type, ref="Control")
model2 <- lm(org ~ type, data=antibio)
summary(model2)
```

#t.test for parvise sammenligninger i ensidet ANOVA 
t-test for sammenligning med referencegruppen foretages automatisk i summary. Hvis vi fitter modellen med kontrolgruppen som reference, udf√∏res testene for sammenligning med kontrollen alts√• for hver af de fem typer antibiotium.

Lad os som eksempel se p√• Fenbendazole og unders√∏ge hypotesen om at den forventede v√¶rdi er den samme for denne gruppe og kontrolgruppen, Œ±Fenb=Œ±Ctrl
Vi afl√¶ser p-v√¶rdien til 0.0028, s√• der er evidens i data for at der er forskel mellem de to grupper.(ses i summary ovenfor)

#F-test ved ensidet ANOVA 

##Sammenligning af tre eller flere grupper 
Vi beskriver variationen i m√•lingerne af organisk stof ved en ensidet variansanalysemodel. Vi antager s√•ledes, at m√•lingerne i hver gruppe er normalfordelte med samme varians, men at middelv√¶rdien kan v√¶re forskellig i de forskellige grupper. Alle m√•linger antages at v√¶re uafh√¶ngige.

Vi kalder populationsmiddelv√¶rdierne i de 6 grupper (givet ved fodertype) for Œ±1,Œ±2,‚Ä¶,Œ±6. Vi √∏nsker at teste en hypotese om, at middelv√¶rdierne er ens i alle grupper
H0:Œ±1=Œ±2=‚Ä¶=Œ±6

F-test: 
```{r}
drop1(model2, test="F")
```
HUSK, denne kun virker, hvis der ikke er "-1" i ligningen. Hvis der er dette, s√• brug summary. 
Vi konkluderer at F-testst√∏rrelsen bliver 7.97 med en tilh√∏rende p-v√¶rdi p√• 8.953e‚àí05. 

##Samme middelv√¶rdi for alle grupper p√•n√¶r kontrolgruppen? 
Vi kunne i stedet v√¶re interesseret i at unders√∏ge, om middelv√¶rdien er ens for alle grupper, bortset fra kontrolgruppen. Dette kan formuleres som

H0:Œ±Alfacyp=Œ±Enroflox=Œ±Fenbenda=Œ±Ivermectin=Œ±Spiramyc - men der ikke er nogle restriktioner p√• middelv√¶rdien h√∏rende til kontrolgruppen.

Vi kan teste hypotesen som en F-test ud fra

en fuld model: hvor de 6 gruppemiddelv√¶rdier tillades at v√¶re forskellige
en nulmodel: med kun to forskellige gruppemiddelv√¶rdier for hhv. kontrolgruppen og en (f√¶lles) v√¶rdi for de √∏vrige 5 grupper

Den fulde model er her blot vores ensidet variansanalyse model, mens nul modellen kan fittes i R ved at lave en ny faktor med to niveauer, som holder styr p√• om m√•lingerne stammer fra kontrolgruppe eller ej.

Variablen typeControl som laves her neden for antager to v√¶rdier: TRUE for m√•linger fra kontrolgruppen og FALSE for alle √∏vrige m√•linger.
```{r}
antibio$typeControl <- (antibio$type == "Control")
fullModel <- lm(org ~ type, data = antibio)
nullModel2 <- lm(org ~ typeControl, data = antibio)
anova(nullModel2, fullModel)
```
Konklusion:  Nulhypotesen forkastes: F = 4.5056 svarende til en p-v√¶rdi p√• 0.006171. Datas√¶ttet underst√∏tter dermed ikke en hypotese om, at middelv√¶rdien er ens for alle grupper p√•n√¶r kontrolgruppen.

#Bonferri-korrektion: multiple t-test: 

Kigger p√• summary over model 2. Ved Bonferroni-korrektion ganges p-v√¶rdierne med antallet af test (her 5) f√∏r man foretager en vurdering af, om p-v√¶rdien er under signifikansniveauet (fx. 5 %). For dette eksempel er der stadig 4 af de 5 nederste p-v√¶rdier som holder sig under 5 %, selvom vi betragter de Bonferroni-korrigerede p-v√¶rdier! Vi f√∏ler os derfor ret sikre p√•, at alle grupper/fodertyper (p√•n√¶r Fenbenda), f√∏rer til et forh√∏jet indhold af organisk materiale i g√∏dningen.


#Analyse af to uafh√¶ngige(uparrede) stikpr√∏ver: 

```{r}
library(isdals)
data("salmon")
```
data er fra to laksepopulationer, som begge blev inficeret med en parasit. Er interesseret i at se forskellen mellem de to populationer 

Laver et boxplot, for at kunne bed√∏mme graden af variationen
```{r}
boxplot(parasites~stock, data=salmon)
```
Udfra boxplottet, virker det fornuftigt at antage der er ens spredninger, men laver alligevel analysen fra begge populationer: 
```{r}
sverige <- subset(salmon, stock=="atran")
skotland <- subset(salmon, stock=="conon")
sd(sverige$parasites)
```
```{r}
sd(skotland$parasites)
```

Antagelse for at spredningen er ens: 
laver derfor en t.test. Default for t.test er (uparret) analyse af to stikpr√∏ver med forskellige spredninger, s√• vi skal eksplicit angive det hvis vi √∏nsker ens spredninger.
```{r}
t.test(sverige$parasites, skotland$parasites, var.equal = TRUE)
```

Antagelse for at spredningen ikke er ens: H0 = beta er lig 0 
```{r}
t.test(sverige$parasites, skotland$parasites)
```
Nul er ikke inkluderet i konfidensintervallerne, s√• en populationsforskel p√• 0 er ikke i overensstemmelse med data p√• 95% konfidensniveau. Det tyder s√•ledes p√• at laks fra Atran og Conon reagerer forskelligt p√• infektion med en parasit af denne type

#Analyse af to parrede stikpr√∏ver 

Eksempel med heste, hvor vi gerne vil finde forskellen i populationsmiddelv√¶rdi for raske og halte heste 
Data er parrede, da der er to observationer fra de samme heste - de kan ikke antages at v√¶re uafh√¶ngige. 
Hypotesen er at middelv√¶rdien for forskellen er nul, alts√• H0:Œº=0

```{r}
data("lameness")
```

Analysen fortages p√• forskellen mellem de to m√•linger, ved brug af t.test: 
```{r}
t.test(lameness$lame - lameness$healthy)
```
Ved denne model, antager jeg dog at jeg bruger forskellen som argument til min t.test 
Nul ligger i ikke konfidensintervallet, s√• denne v√¶rdi af populationsforskel er ikke i overensstemmelse med data. Det tyder s√•ledes p√• at symmetriscoren faktisk √¶ndrer sig n√•r heste bliver halte.
Samtidig, er min p-v√¶rdi=0,00031% som ligger langt undfer 0,05% og derfor forkastes hypotesen 

MODELKONTROL: 
#Modelkontrol for line√¶r regression 

Den grundl√¶ggende antagelse er at m√•lingerne af hjertev√¶gt (y = Hwt) for en fast kropsv√¶gt (x = Bwt) i gennemsnit ligger p√• en ret linje: E(y)=Œ±+Œ≤‚ãÖx

og at variation omkring regressionslinjen kan beskrives ud fra fejl-led (eng: remainder terms) e1,‚Ä¶,en som: - har middelv√¶rdi 0
- har samme spredning
- er normalfordelt
- er uafh√¶ngige
Vi kontrollerer modelantagelserne ved at se p√• de standardiserede residualer. F√∏lgende figurer kan v√¶re relevante:
- et residualplot af de standardiserede residualer mod de fittede v√¶rdier
- et residualplot af de standardiserede residualer mod den forklarende variabel x (dvs. Bwt)
- et QQ-plot af de standardiserede residualer

##Residualplot: 
```{r}
plot(fitted(linreg), rstandard(linreg))
abline(h=0, lty=2)
plot(cats$Bwt, rstandard(linreg))
abline(h=0, lty=2)

```
Vi konkluderer at:
gennemsnittet af residualerne er ca. 0 uanset v√¶rdien af gruppegennemsnittet (predicted values)
der er ca. samme spredning af residualerne i alle grupper (varianshomogenitet)

##QQ-plot: 
```{r}
qqnorm(rstandard(linreg))
abline(0, 1, lwd=2)
```
P√• baggrund af QQ-plottet konkluderes at:
punkterne afviger ikke systematisk fra den rette linje
dette fortolkes som at de standardiserede residualer med god tiln√¶rmelse kan antages at f√∏lge en standardnormalfordeling (med middelv√¶rdi 0 og varians 1)

##Pr√¶diktions- og konfidensintervaller: 
```{r}
con <-  predict(linreg, newdata, interval="c") #confidens
pre <- predict(linreg, newdata, interval="p") #pr√¶diktions
```

#Modelkontrol for ensidet ANOVA 

Den grundl√¶ggende antagelse er at m√•lingernes variation omkring gruppegennemsnittet kan beskrives ud fra fejlled (eng: remainder terms) e1,‚Ä¶,en som
- har middelv√¶rdi 0
- har samme spredning
- er normalfordelt
- er uafh√¶ngige
I praksis unders√∏ges modelantagelserne ved at udregne residualerne, som kan udtr√¶kkes fra den ensidede variansanalysemodel med resid().

```{r}
resid(model2)
```
Kan ikke bruges disse, da det kun er observationer af organisk stof fratrukket gennemsnittet for fodertype. 
Skal derfor finde de standardiserede residualer: 
```{r}
rstandard(model2)
```

Skal igen lave et residualplot og et QQ-plot, ligesom der g√∏res i line√¶re og kvardratisk regression (se ovenover)


#MODELKONTROL for tosidet ANOVA 

Laver f√∏rst residualplot: 
```{r}
plot(fitted(modelulog), rstandard(modelulog), pch = 16, main = "ANOVA", cex.main = 1.5, cex.lab = 1.5)
abline(h = 0, lty = 2)
```

Laver derefter QQ-plot: 
```{r}
qqnorm(rstandard(modelulog), main="QQ-plot for ANOVA", pch = 16)
abline(0, 1, lwd = 2, lty = 2)
```


#Multipel line√¶r regression p√• utransformerede data 

```{r}
library(isdals)
data(trees)
```
Data indeholder tre kontinuerte variable: 
Volume: tr√¶ets volumen i cubit feet (respons)
Height: tr√¶ets h√∏jde i feet (forklarende variabel)
Girth: tr√¶ets diamenter i inches (forklarende variabel)

Fitter f√∏rst en multipel line√¶r regressionsmodel
```{r}
multipell <- lm(Volume ~ Height + Girth, data=trees)
summary(multipell)

```
Fortolkning: 
Kan se ud fra summary, at modellen udtrykker at det forventede volume kan udtrykkes ved ligningen: 
ùöÖùöòùöïùöûùöñùöé=Œ±+Œ≤1‚ãÖùô∑ùöéùöíùöêùöëùöù+Œ≤2‚ãÖùô∂ùöíùöõùöùùöë

De tre datalinjer (under Coefficients) vedr√∏rer:
(Intercept): estimat, SE, test for parameteren Œ±
Height: estimat, SE, test for parameteren 1
Girth: estimat, SE, test for parameteren Œ≤2
Specielt kan vi af outputtet l√¶se at det forventede volumen √∏ges med 4.71 (cubic feet) hvis tr√¶ets diameter √∏ges med 1 inch (hvis ellers h√∏jden er u√¶ndret) 


#Multipel line√¶r regression p√• logtransformerede data 

```{r}
multipel2 <- lm(log(Volume) ~ log(Height) + log(Girth), data=trees)
summary(multipel2)
```
Fortolkning: Modellen udtrykker at det forventede log(Volume) kan udtrykkes ved en ligning af formen
ùöïùöòùöê(ùöÖùöòùöïùöûùöñùöé)=Œ±+Œ≤1‚ãÖùöïùöòùöê(ùô∑ùöéùöíùöêùöëùöù)+Œ≤2‚ãÖùöïùöòùöê(ùô∂ùöíùöõùöùùöë)

De tre datalinjer (under Coefficients) vedr√∏rer

(Intercept): estimat, SE, test for parameteren Œ±
log(Height): estimat, SE, test for parameteren Œ≤1
log(Girth): estimat, SE, test for parameteren Œ≤2
Specielt kan vi af outputtet l√¶se den gennemsnitlige v√¶rdi af log(Volume) √∏ges med 1.98 (cubic feet) hvis logaritmen til tr√¶ets diameter (dvs. log(Girth)) √∏ges med 1 inch (hvis ellers h√∏jden er u√¶ndret)
medianen af Volume √∏ges med en faktor exp(1.983) = 7.265 hvis logaritmen til tr√¶ets diameter (dvs. log(Girth)) √∏ges med 1 (hvis ellers h√∏jden er u√¶ndret).

Vi bliver ikke n√∏dvendigvis s√• meget klogere af tallene ovenfor, fordi det kan v√¶re sv√¶rt at vurdere, hvad det egentlig betyder, at log(Girth) √∏ges med 1. En mulig fortolkning er dog f√∏lgende
Hvis Girth bliver dobbelt s√• stor, s√• √∏ges log(Girth) med log(2)=0.693, og s√• √∏ges medianen for Volume med en faktor exp(0.693*1.983)=3.95. I grove tr√¶k vil en fordobling (x 2) af diameteren (Girth) alts√• modsvares af en firdobling (x 4) af medianen for Volume (hvis ellers h√∏jden er u√¶ndret)

##Test af nulhypotese Œ≤1=1, Œ≤2=2 

Vi interesserer os for, om sammenh√¶ngen ml. Volume og (Height, Girth) kan beskrives ved en ligning af formen

ùöÖùöòùöïùöûùöñùöé=c‚ãÖùô∑ùöéùöíùöêùöëùöù‚ãÖùô∂ùöíùöõùöùùöë2

Dette svarer (efter log-transformation) til en ligning af formen ùöïùöòùöê(ùöÖùöòùöïùöûùöñùöé)=log(c)+1‚ãÖùöïùöòùöê(ùô∑ùöéùöíùöêùöëùöù)+2‚ãÖùöïùöòùöê(ùô∂ùöíùöõùöùùöë)

Dette kan opfattes som en restriktion af parametrene i den multiple line√¶re regressionsmodel
ùöïùöòùöê(ùöÖùöòùöïùöûùöñùöé)i=Œ±+Œ≤1‚ãÖùöïùöòùöê(ùô∑ùöéùöíùöêùöëùöù)i+Œ≤2‚ãÖùöïùöòùöê(ùô∂ùöíùöõùöùùöë)i+ei
hvor vi s√¶tter Œ≤1=1 og Œ≤2=2
vi kan teste hypotesen H0:Œ≤1=1,Œ≤2=2 ved at fortage en sammenligne (med anova()) af
en fuld model: den multiple line√¶re regressionsmodel (kaldet multipel2 ovenfor)
en nul model: den multiple line√¶re regressionsmodel, hvor vi tvinger Œ≤1 til at v√¶re 1 og Œ≤2 til at v√¶re 2 (men hvor Œ± stadig kan estimeres frit)

Bruger offset, for at tvinge et led ned over modellen, som har en bestem form. Tvinger leddet s√•ledes: 1‚ãÖùöïùöòùöê(ùô∑ùöéùöíùöêùöëùöù)i+2‚ãÖùöïùöòùöê(ùô∂ùöíùöõùöùùöë)i
R vil derfor kun estimere intercept. 

Jeg sammenligner derfor den estimerede model, som er min nulmodel med den fulde model
```{r}
naiv <- lm(log(Volume) ~ offset(1*log(Height) + 2*log(Girth)), data=trees)
anova(naiv, multipel2)
```
Konklusion: Kan se, at vi har en p-v√¶rdi p√• 0,85% og derfor v√¶lger vi acceptere nulhypotesen. 


#Teste en line√¶r regressionsmodel mod en ensidet ANOVA model 

**Udf√∏r et statistisk test, hvor du sammenligner model1 og model2. Forklar hvad man kan konkludere ud fra dette**

De to modeller kan testes ved en F-test: 
```{r}
anova(model1, model2)
```
P-v√¶rdien ligger p√• 0,14% og ligger derfor under signifikansniveauet. Derfor forkastes modellen, som udtrykker, at der en line√¶r sammenh√¶ng mellem tilsat nitratm√¶ngde og m√¶ngden af t√∏rstof.


#Tosidet ANOVA med og uden vekselvirkning 

- Hvorfor skal man benytte en tosidet variansanalyse? 
Det ville v√¶re oplagt at skulle bruge en tosidet variansanalyse, da jeg har en kontinuert responsvariabel og to kategoriske forklarende variabler. 

#MED vekselvirkning: 

Estimer en R-kode; 
```{r}
modelulog <- lm(figur2 ~ studie+kon+studie*kon, data=ss2017_18)
```

- Unders√∏g med et hypotesetest om der er vekselvikrning mellem k√∏n og studie
Nulhypotese: Der er ikke vekselvirkning mellem k√∏n og studie. 

Laver en F-test: 
```{r}
drop1(modelmlog, test="F")
```
Kan se, at jeg f√•r en p-v√¶rdi p√• 0,07% og derfor v√¶lger jeg at acceptere min nulhypotese og der er derfor ikke vekselvirkning mellem k√∏n og studie. 

#UDEN vekselvirkning 

Estimer model: 
```{r}
nymodel <- lm(log(figur2) ~ studie+kon, data=ss2017_18)
```

- Find estimat og 95% konfidensinterval
Estimat: 
```{r}
summary(nymodel)
```

95% konfidensinterval: 
```{r}
confint(nymodel)
```


- Angiv et estimat for forskellen mellem kvinder og m√¶nd i forventet v√¶rdi af log(figur2)
Kan ud fra summary afl√¶se, at der er en forskel p√• -0.211680 

Skal finde faktoren, s√• bruger exp: 
```{r}
exp(-0.211680)
```
Dette er faktoren for m√¶nds g√¶t er lavere end kvinder er derfor  0.8092236.


**Uafh√¶ngighedstest**

*Forklar hvorfor den relevantehypotese er en hypotese om uafh√¶ngighed snarere end en hypotese om ens sandsynligheder i to binomialfordelinger*

Det er en homogenitetsanalyse, da det omhandler om der er samme sandsynlighed for at ende i de samme responsgrupper 

*Udf√∏r et test for uafh√¶ngighed, og forklar hvad resultatet siger om forekomsten af stress i virksomheder. Forekommer det tilf√¶ldigt over tid eller snarere i "i klumper".*

Nulhypotese: Der er ingen sammenh√¶ng/uafh√¶ngige mellem stressniveauet i m√•ned 1 og m√•ned 2
```{r}
stress <- matrix(c(14, 51, 52, 401), 2,2)
stress
```
Laver en test for uafh√¶ngighed: 
```{r}
chisq.test(stress, correct= TRUE)
```
Da vi har en p-v√¶rdi p√• 0,03% skal den derfor forkastes, og man kan derfor p√•pege, at der er en sammenh√¶ng/ikke uafh√¶ngige mellem stressniveauet i de to m√•neder. 


**Binomial**

1. *Forklar hvorfor bionomialfordelingen skal bruges til dette*
Da der er en vis sandsynlighed for, enten at g√¶tte rigtigt eller g√¶tte forkert og netop da antallet er optalt og derfor er diskrete tal 

2. *Bestem et estimat for p* 
```{r}
#p = antal sucesser/ antal fors√∏g 
 13/20
```
S√• estimatet for p = 0,65

3. *Bestem to 95% konfidensintervaller for p: b√•de det simple og det forbedrede Det simple: 
```{r}
0.65-1.96*sqrt((0.65*(1-0.65))/20)
```
```{r}
0.65+1.96*sqrt((0.65*(1-0.65))/20)
```
Det simple interval er derfor [0.4409589 , 0.8590411]

Det forbedrede interval: 
```{r}
prop.test(13, 20, correct=FALSE)
```
Forbedrede interval [0.4328543 , 0.8188082]

4.*Hvilken hypotese svarer til at personerne ikke kan smage forskel p√• de to colaer? test ved binom.test - hvad er konklusionen?*

Nulhypotese= p=1/2 
```{r}
binom.test(13, 20, p=1/2)
```
P-v√¶rdien ligger p√• 0,26% og derfor accepterer jeg nulhypotesen om, at min p=1/2 er korrekt, hvis de g√¶ttede.


**pbinom og dbinom**

dbinom viser sandsynlighed for bestemt antal succeser
og pbinom viser sadsynlighed for at f√• bestemt antal succeser eller mindre. 

*I 2019 var 40% af de studerende indskrevet til biotek. Hvad lodtr√¶kning udv√¶lges 10 studerende - hvad er sandsynligheden for, at der er h√∏jst 5 studerende fra biotek som udv√¶lges?*

```{r}
pbinom(5, size=10, prob=0.40)
```

HUSK: 
Hvis du skal have fire rigtige ud af 10, s√• skal man bruge PNORM. 
Men hvis du skal have fire eller flere rigtige ud af 10, s√• skal du bruge 1- pnorm 

